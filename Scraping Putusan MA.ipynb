{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas requests beautifulsoup4 pdfminer.six lxml > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "NtAHMjrSwKK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TVDe3K5u_4c"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import urllib\n",
        "from concurrent.futures import ThreadPoolExecutor, wait\n",
        "from datetime import date\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pdfminer import high_level\n",
        "\n",
        "\n",
        "\n",
        "# def get_args(argv=None):\n",
        "#     parser = argparse.ArgumentParser(\n",
        "#         description=\"Putusan Mahkamah Agung Scraper\", add_help=True\n",
        "#     )\n",
        "#     parser.add_argument(\n",
        "#         \"-k\",\n",
        "#         \"--keyword\",\n",
        "#         required=False,\n",
        "#         dest=\"keyword\",\n",
        "#         help=\"keyword for the Supreme Court\",\n",
        "#     )\n",
        "#     parser.add_argument(\n",
        "#         \"-u\",\n",
        "#         \"--url\",\n",
        "#         required=False,\n",
        "#         dest=\"url\",\n",
        "#         help=\" specify url for the Supreme Court\\nexample: https://putusan3.mahkamahagung.go.id/search.html?cat=98821d8a4bc63aff3a81f66c37934f56\",\n",
        "#     )\n",
        "#     parser.add_argument(\n",
        "#         \"-sd\",\n",
        "#         \"--sortdate\",\n",
        "#         dest=\"sort_date\",\n",
        "#         required=False,\n",
        "#         default=False,\n",
        "#         action=\"store_true\",\n",
        "#         help=\"(optional) scraping from newest putusan. Default False\",\n",
        "#     )\n",
        "#     parser.add_argument(\n",
        "#         \"-dp\",\n",
        "#         \"--downloadpdf\",\n",
        "#         dest=\"download_pdf\",\n",
        "#         required=False,\n",
        "#         default=False,\n",
        "#         action=\"store_true\",\n",
        "#         help=\"(optional) download pdf. Default False\",\n",
        "#     )\n",
        "#     return parser.parse_args(argv)\n",
        "\n",
        "def create_path(folder_name):\n",
        "  path = os.path.join(os.getcwd(), folder_name)\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  return path\n",
        "\n",
        "def open_page(link):\n",
        "    count = 0\n",
        "    while count < 3:\n",
        "        try:\n",
        "            return BeautifulSoup(requests.get(link).text, \"lxml\")\n",
        "        except:\n",
        "            count += 1\n",
        "            time.sleep(5)\n",
        "\n",
        "\n",
        "def get_detail(soup, keyword):\n",
        "    try:\n",
        "        text = (\n",
        "            soup.find(lambda tag: tag.name == \"td\" and keyword in tag.text)\n",
        "            .find_next()\n",
        "            .get_text()\n",
        "            .strip()\n",
        "        )\n",
        "        return text\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def get_pdf(url, path_pdf):\n",
        "    file = urllib.request.urlopen(url)\n",
        "    file_name = file.info().get_filename().replace(\"/\", \" \")\n",
        "    file_content = file.read()\n",
        "    with open(f\"{path_pdf}/{file_name}\", \"wb\") as out_file:\n",
        "            out_file.write(file_content)\n",
        "    return io.BytesIO(file_content), file_name\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.replace(\"M a h ka m a h A g u n g R e p u blik In d o n esia\\n\", \"\")\n",
        "    text = text.replace(\"Disclaimer\\n\", \"\")\n",
        "    text = text.replace(\n",
        "        \"Kepaniteraan Mahkamah Agung Republik Indonesia berusaha untuk selalu mencantumkan informasi paling kini dan akurat sebagai bentuk komitmen Mahkamah Agung untuk pelayanan publik, transparansi dan akuntabilitas\\n\",\n",
        "        \"\",\n",
        "    )\n",
        "    text = text.replace(\n",
        "        \"pelaksanaan fungsi peradilan. Namun dalam hal-hal tertentu masih dimungkinkan terjadi permasalahan teknis terkait dengan akurasi dan keterkinian informasi yang kami sajikan, hal mana akan terus kami perbaiki dari waktu kewaktu.\\n\",\n",
        "        \"\",\n",
        "    )\n",
        "    text = text.replace(\n",
        "        \"Dalam hal Anda menemukan inakurasi informasi yang termuat pada situs ini atau informasi yang seharusnya ada, namun belum tersedia, maka harap segera hubungi Kepaniteraan Mahkamah Agung RI melalui :\\n\",\n",
        "        \"\",\n",
        "    )\n",
        "    text = text.replace(\n",
        "        \"Email : kepaniteraan@mahkamahagung.go.id    Telp : 021-384 3348 (ext.318)\\n\",\n",
        "        \"\",\n",
        "    )\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_data(link, keyword_url):\n",
        "    global today\n",
        "    global path_output\n",
        "    global path_pdf\n",
        "    global download_pdf\n",
        "\n",
        "    path_output = create_path(\"txt_putusan\")\n",
        "    path_pdf = create_path(\"pdf_putusan\")\n",
        "    today = date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    soup = open_page(link)\n",
        "    table = soup.find(\"table\", {\"class\": \"table\"})\n",
        "    judul = table.find(\"h2\").text\n",
        "    #soup.find(\"table\", {\"class\": \"table\"}).find(\"h2\").decompose()\n",
        "    table.find(\"h2\").decompose()\n",
        "\n",
        "    nomor = get_detail(table, \"Nomor\")\n",
        "    tingkat_proses = get_detail(table, \"Tingkat Proses\")\n",
        "    klasifikasi = get_detail(table, \"Klasifikasi\")\n",
        "    kata_kunci = get_detail(table, \"Kata Kunci\")\n",
        "    tahun = get_detail(table, \"Tahun\")\n",
        "    tanggal_register = get_detail(table, \"Tanggal Register\")\n",
        "    lembaga_peradilan = get_detail(table, \"Lembaga Peradilan\")\n",
        "    jenis_lembaga_peradilan = get_detail(table, \"Jenis Lembaga Peradilan\")\n",
        "    hakim_ketua = get_detail(table, \"Hakim Ketua\")\n",
        "    hakim_anggota = get_detail(table, \"Hakim Anggota\")\n",
        "    panitera = get_detail(table, \"Panitera\")\n",
        "    amar = get_detail(table, \"Amar\")\n",
        "    amar_lainnya = get_detail(table, \"Amar Lainnya\")\n",
        "    catatan_amar = get_detail(table, \"Catatan Amar\")\n",
        "    tanggal_musyawarah = get_detail(table, \"Tanggal Musyawarah\")\n",
        "    tanggal_dibacakan = get_detail(table, \"Tanggal Dibacakan\")\n",
        "    kaidah = get_detail(table, \"Kaidah\")\n",
        "    abstrak = get_detail(table, \"Abstrak\")\n",
        "\n",
        "    try:\n",
        "        link_pdf = soup.find(\"a\", href=re.compile(r\"/pdf/\"))[\"href\"]\n",
        "        file_pdf, file_name_pdf = get_pdf(link_pdf, path_pdf)\n",
        "        text_pdf = high_level.extract_text(file_pdf)\n",
        "        text_pdf = clean_text(text_pdf)\n",
        "    except:\n",
        "        link_pdf = \"\"\n",
        "        text_pdf = \"\"\n",
        "        file_name_pdf = \"\"\n",
        "\n",
        "    data = [\n",
        "        judul,\n",
        "        nomor,\n",
        "        tingkat_proses,\n",
        "        klasifikasi,\n",
        "        kata_kunci,\n",
        "        tahun,\n",
        "        tanggal_register,\n",
        "        lembaga_peradilan,\n",
        "        jenis_lembaga_peradilan,\n",
        "        hakim_ketua,\n",
        "        hakim_anggota,\n",
        "        panitera,\n",
        "        amar,\n",
        "        amar_lainnya,\n",
        "        catatan_amar,\n",
        "        tanggal_musyawarah,\n",
        "        tanggal_dibacakan,\n",
        "        kaidah,\n",
        "        abstrak,\n",
        "        link,\n",
        "        link_pdf,\n",
        "        file_name_pdf,\n",
        "        text_pdf,\n",
        "    ]\n",
        "    result = pd.DataFrame(\n",
        "        [data],\n",
        "        columns=[\n",
        "            \"judul\",\n",
        "            \"nomor\",\n",
        "            \"tingkat_proses\",\n",
        "            \"klasifikasi\",\n",
        "            \"kata_kunci\",\n",
        "            \"tahun\",\n",
        "            \"tanggal_register\",\n",
        "            \"lembaga_peradilan\",\n",
        "            \"jenis_lembaga_peradilan\",\n",
        "            \"hakim_ketua\",\n",
        "            \"hakim_anggota\",\n",
        "            \"panitera\",\n",
        "            \"amar\",\n",
        "            \"amar_lainnya\",\n",
        "            \"catatan_amar\",\n",
        "            \"tanggal_musyawarah\",\n",
        "            \"tanggal_dibacakan\",\n",
        "            \"kaidah\",\n",
        "            \"abstrak\",\n",
        "            \"link\",\n",
        "            \"link_pdf\",\n",
        "            \"file_name_pdf\",\n",
        "            \"text_pdf\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    keyword_url = keyword_url.replace(\"/\", \" \")\n",
        "    if keyword_url.startswith(\"https\"):\n",
        "        keyword_url = \"\"\n",
        "\n",
        "    destination = f\"{path_output}/putusan_ma_{keyword_url}_{today}\"\n",
        "    print(destination)\n",
        "    if not os.path.isfile(f\"{destination}.csv\"):\n",
        "        result.to_csv(f\"{destination}.csv\", header=True, index=False)\n",
        "    else:\n",
        "        result.to_csv(f\"{destination}.csv\", mode=\"a\", header=False, index=False)\n",
        "\n",
        "def run_scraper(keyword=None, url=None, sort_date=True, download_pdf=True):\n",
        "  if not keyword and not url:\n",
        "    print(\"please url\")\n",
        "    return\n",
        "\n",
        "  path_output = create_path(\"putusan\")\n",
        "  path_pdf = create_path(\"pdf-putusan\")\n",
        "\n",
        "  today = date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  link = f\"https://putusan3.mahkamahagung.go.id/search.html?q={keyword}&page-1\"\n",
        "\n",
        "  if url:\n",
        "    link = url\n",
        "\n",
        "  soup = open_page(link)\n",
        "\n",
        "  last_page = int(\n",
        "      soup.find_all(\"a\", {\"class\": \"page-link\"})[-1].get(\"data-ci-pagination-page\")\n",
        "  )\n",
        "\n",
        "  if url:\n",
        "    print(f\"Scraping with url: {url} - {20 * last_page} data - {last_page} page\")\n",
        "  else:\n",
        "    print(f\"scraping with keyword:{keyword} - {20*last_page}data - {last_page} page\")\n",
        "\n",
        "  if url:\n",
        "    keyword_url = url\n",
        "  else:\n",
        "    keyword_url = keyword\n",
        "\n",
        "  futures = []\n",
        "  with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    for page in range(last_page):\n",
        "      futures.append(\n",
        "          executor.submit(run_process, keyword_url, page+1, sort_date)\n",
        "      )\n",
        "  wait(futures)\n",
        "\n",
        "def run_process(keyword_url, page, sort_page):\n",
        "    if keyword_url.startswith(\"https\"):\n",
        "        link = f\"{keyword_url}&page={page}\"\n",
        "    else:\n",
        "        link = f\"https://putusan3.mahkamahagung.go.id/search.html?q={keyword_url}&page={page}\"\n",
        "    if sort_page:\n",
        "        link = f\"{link}&obf=TANGGAL_PUTUS&obm=desc\"\n",
        "\n",
        "    print(link)\n",
        "\n",
        "    soup = open_page(link)\n",
        "    links = soup.find_all(\"a\", {\"href\": re.compile(\"/direktori/putusan\")})\n",
        "\n",
        "    for link in links:\n",
        "        extract_data(link[\"href\"], keyword_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_scraper(url=\"https://putusan3.mahkamahagung.go.id/search.html?q=&jenis_doc=putusan&cat=3c40e48bbab311301a21c445b3c7fe57&jd=&tp=&court=400172PN356+++++++++++++++++++++&t_put=2023&t_reg=&t_upl=&t_pr=\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HIC1qbgwInu",
        "outputId": "703e059d-05f9-48cf-b95e-d421a800a374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping with url: https://putusan3.mahkamahagung.go.id/search.html?q=&jenis_doc=putusan&cat=3c40e48bbab311301a21c445b3c7fe57&jd=&tp=&court=400172PN356+++++++++++++++++++++&t_put=2023&t_reg=&t_upl=&t_pr= - 40 data - 2 page\n",
            "https://putusan3.mahkamahagung.go.id/search.html?q=&jenis_doc=putusan&cat=3c40e48bbab311301a21c445b3c7fe57&jd=&tp=&court=400172PN356+++++++++++++++++++++&t_put=2023&t_reg=&t_upl=&t_pr=&page=1&obf=TANGGAL_PUTUS&obm=desc\n",
            "https://putusan3.mahkamahagung.go.id/search.html?q=&jenis_doc=putusan&cat=3c40e48bbab311301a21c445b3c7fe57&jd=&tp=&court=400172PN356+++++++++++++++++++++&t_put=2023&t_reg=&t_upl=&t_pr=&page=2&obf=TANGGAL_PUTUS&obm=desc\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n",
            "/content/txt_putusan/putusan_ma__2023-11-12\n"
          ]
        }
      ]
    }
  ]
}